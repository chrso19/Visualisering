{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4735e944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygbif import occurrences\n",
    "from pygbif import species\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4376a3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Danish name        English name             Latin name  \\\n",
      "0                  Karl Johan             Porcino         Boletus edulis   \n",
      "1          Brunstokket Rørhat          Bay bolete          Imleria badia   \n",
      "2  Punktstokket Indigo-Rørhat   Scarletina bolete   Boletus luridiformis   \n",
      "3    Netstokket Indigo-Rørhat  Suillellus luridus        Boletus luridus   \n",
      "4         Almindelig Kantarel  Golden chanterelle  Cantharellus cibarius   \n",
      "\n",
      "  Category  speciesKey  taxonKey   ourID  \n",
      "0   Funghi     5954958   5954958  OUR001  \n",
      "1   Funghi     7832732   7832732  OUR002  \n",
      "2   Funghi     8208185   5954922  OUR003  \n",
      "3   Funghi     3355021   7988694  OUR004  \n",
      "4   Funghi     5249504   5249504  OUR005  \n"
     ]
    }
   ],
   "source": [
    "plant_names = pd.read_csv('plant_names.csv', sep=';')\n",
    "\n",
    "if \"speciesKey\" not in plant_names.columns:\n",
    "    plant_names[\"speciesKey\"] = None\n",
    "if \"taxonKey\" not in plant_names.columns:\n",
    "    plant_names[\"taxonKey\"] = None\n",
    "if \"ourID\" not in plant_names.columns:\n",
    "    plant_names[\"ourID\"] = None\n",
    "\n",
    "for idx, row in plant_names.iterrows():\n",
    "    if row[\"ourID\"] == None:\n",
    "        plant_names.at[idx, \"ourID\"] = \"OUR\"+str(idx+1).zfill(3)\n",
    "    if row[\"speciesKey\"] == None or row[\"taxonKey\"] == None:\n",
    "        try:\n",
    "            # Slå op i GBIF backbone\n",
    "            match = species.name_backbone(name=row[\"Latin name\"], rank=\"species\")\n",
    "            taxonKey = match.get(\"usageKey\")          # præcist matchet navn\n",
    "            speciesKey = match.get(\"speciesKey\") or taxonKey  # accepted species\n",
    "            \n",
    "            plant_names.at[idx, \"taxonKey\"] = taxonKey\n",
    "            plant_names.at[idx, \"speciesKey\"] = speciesKey\n",
    "            \n",
    "            # print(f'Added keys for {row[\"Danish name\"]}: taxonKey={taxonKey}, speciesKey={speciesKey}')\n",
    "        except Exception as e:\n",
    "            print(f'Could not match {row[\"Latin name\"]}: {e}')\n",
    "\n",
    "print(plant_names.head())            \n",
    "if False:\n",
    "    plant_names.to_csv(\"plant_names.csv\",sep=';', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24b06598",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "GBIF_USER not supplied and no entry in environmental\n                           variables",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     10\u001b[39m query = {\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mand\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpredicates\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     ]\n\u001b[32m     33\u001b[39m }\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# --- Opret download ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m download_key, _ = \u001b[43moccurrences\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memail\u001b[49m\u001b[43m=\u001b[49m\u001b[43memail\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpwd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpwd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDownload key:\u001b[39m\u001b[33m\"\u001b[39m, download_key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anna\\Documents\\SDU\\Visualisering\\Project\\Visualisering\\venv\\Lib\\site-packages\\pygbif\\occurrences\\download.py:251\u001b[39m, in \u001b[36mdownload\u001b[39m\u001b[34m(queries, format, user, pwd, email, pred_type)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdownload\u001b[39m(\n\u001b[32m     79\u001b[39m     queries, \u001b[38;5;28mformat\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mSIMPLE_CSV\u001b[39m\u001b[33m\"\u001b[39m, user=\u001b[38;5;28;01mNone\u001b[39;00m, pwd=\u001b[38;5;28;01mNone\u001b[39;00m, email=\u001b[38;5;28;01mNone\u001b[39;00m, pred_type=\u001b[33m\"\u001b[39m\u001b[33mand\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     80\u001b[39m ):\n\u001b[32m     81\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[33;03m    Spin up a download request for GBIF occurrence data.\u001b[39;00m\n\u001b[32m     83\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    248\u001b[39m \n\u001b[32m    249\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     user = \u001b[43m_check_environ\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGBIF_USER\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m     pwd = _check_environ(\u001b[33m\"\u001b[39m\u001b[33mGBIF_PWD\u001b[39m\u001b[33m\"\u001b[39m, pwd)\n\u001b[32m    253\u001b[39m     email = _check_environ(\u001b[33m\"\u001b[39m\u001b[33mGBIF_EMAIL\u001b[39m\u001b[33m\"\u001b[39m, email)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anna\\Documents\\SDU\\Visualisering\\Project\\Visualisering\\venv\\Lib\\site-packages\\pygbif\\occurrences\\download.py:64\u001b[39m, in \u001b[36m_check_environ\u001b[39m\u001b[34m(variable, value)\u001b[39m\n\u001b[32m     62\u001b[39m value = os.environ.get(variable)\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_none(value):\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m                \u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;250;43m                \u001b[39;49m\u001b[33;43;03m\"\"\" not supplied and no entry in environmental\u001b[39;49;00m\n\u001b[32m     69\u001b[39m \u001b[33;43;03m                   variables\"\"\"\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anna\\Documents\\SDU\\Visualisering\\Project\\Visualisering\\venv\\Lib\\site-packages\\pygbif\\gbifutils.py:85\u001b[39m, in \u001b[36mstop\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstop\u001b[39m(x):\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(x)\n",
      "\u001b[31mValueError\u001b[39m: GBIF_USER not supplied and no entry in environmental\n                           variables"
     ]
    }
   ],
   "source": [
    "country_code = \"DK\"\n",
    "start_year = 2023\n",
    "user = os.getenv(\"GBIF_USER\")   # Sæt disse i dine miljøvariabler\n",
    "email = os.getenv(\"GBIF_EMAIL\") # GBIF_EMAIL\n",
    "pwd = os.getenv(\"GBIF_PWD\") \n",
    "\n",
    "\n",
    "taxonKeys = list(plant_names[\"taxonKey\"])\n",
    "# --- JSON query med flere predicates ---\n",
    "query = {\n",
    "    \"type\": \"and\",\n",
    "    \"predicates\": [\n",
    "        {\n",
    "            \"type\": \"in\",\n",
    "            \"key\": \"TAXON_KEY\",\n",
    "            \"values\": [str(tk) for tk in taxonKeys]\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"equals\",\n",
    "            \"key\": \"COUNTRY\",\n",
    "            \"value\": country_code\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"greaterThanOrEquals\",\n",
    "            \"key\": \"YEAR\",\n",
    "            \"value\": start_year\n",
    "        },\n",
    "        { \"type\": \"in\",\n",
    "          \"key\": \"BASIS_OF_RECORD\",\n",
    "          \"values\": [\"OBSERVATION\", \"MACHINE_OBSERVATION\", \"HUMAN_OBSERVATION\"]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# --- Opret download ---\n",
    "download_key, _ = occurrences.download(query, user=user, email=email, pwd=pwd)\n",
    "\n",
    "print(\"Download key:\", download_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b978f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 0001207-251120083545085.zip\n",
      "open file: 0001207-251120083545085.csv\n"
     ]
    }
   ],
   "source": [
    "# GBIF download key\n",
    "# 20/11 2025 kl 19: key = 0001019-251120083545085\n",
    "# 20/11 2025 kl 21: key = 0001207-251120083545085\n",
    "download_key = \"0001207-251120083545085\"\n",
    "\n",
    "\n",
    "# occurrences.download_get(download_key, path=\".\")\n",
    "\n",
    "zip_path = f\"{download_key}.zip\"\n",
    "print(f\"Downloaded {zip_path}\")\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "    # Tag den første fil i zip (typisk occurrence-fil)\n",
    "    occurrence_file = z.namelist()[0]\n",
    "    print(\"open file:\", occurrence_file)\n",
    "    \n",
    "    with z.open(occurrence_file) as f:\n",
    "        # Prøv tab-separeret først, hvis fejl prøv med ',' som separator\n",
    "        try:\n",
    "            df = pd.read_csv(f, sep='\\t', low_memory=False)\n",
    "        except pd.errors.ParserError:\n",
    "            f.seek(0)\n",
    "            df = pd.read_csv(f, sep=',', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1585a84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding name to datasets\n",
    "from pygbif import registry \n",
    "\n",
    "\n",
    "keys = df[\"datasetKey\"].unique()\n",
    "key_to_name_map = {}\n",
    "\n",
    "\n",
    "for key in keys:\n",
    "    try:\n",
    "        # Hent metadata\n",
    "        metadata = registry.datasets(uuid=key)\n",
    "        \n",
    "        # Gem titlen i ordbogen\n",
    "        key_to_name_map[key] = metadata['title']\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Hvis noget går galt (f.eks. ugyldig nøgle), sæt en placeholder\n",
    "        print(f\"Fejl ved hentning af {key}: {e}\")\n",
    "        key_to_name_map[key] = \"Unknown Dataset\"\n",
    "\n",
    "# 3. Opret den nye kolonne ved at 'mappe' nøglerne til navnene\n",
    "df['datasetName'] = df['datasetKey'].map(key_to_name_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4889e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows: 113510\n",
      "number of rows: 98904\n"
     ]
    }
   ],
   "source": [
    "print(\"number of rows:\", len(df))\n",
    "\n",
    "# Licenser. NB! \"CC_BY_NC_4_0\" og \"CC_BY_NC_SA_4_0\" duer ikke til kommercielt brug - men er et studieprojekt kommercielt brug? - vi skal lige have styr på det\n",
    "allowed = [\"CC0\", \"CC_BY_4_0\", \"CC_BY_SA_4_0\"]\n",
    "df= df[df['license'].isin(allowed)]\n",
    "\n",
    "print(\"number of rows:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be0f69d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict(zip(plant_names[\"speciesKey\"], plant_names[\"ourID\"]))\n",
    "df[\"ourID\"] = df[\"speciesKey\"].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "658121af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plants = pd.merge(df[['taxonKey', 'kingdom', 'phylum', 'class', 'order', \n",
    "                  'family', 'genus', 'species']].drop_duplicates('taxonKey'), plant_names, how = 'left', on = 'taxonKey')\n",
    "\n",
    "observations = df[['ourID','speciesKey','taxonKey', 'eventDate', 'year', 'month', 'day',\n",
    " 'decimalLatitude', 'decimalLongitude', \n",
    " 'coordinateUncertaintyInMeters',\n",
    " 'basisOfRecord', 'datasetKey',\n",
    " 'datasetName','recordedBy',\n",
    " 'individualCount', 'occurrenceID', 'gbifID', 'license']]\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d110fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save = {\n",
    "    'plants': plants,\n",
    "    'observations': observations\n",
    "}\n",
    "\n",
    "# Gem til pickle\n",
    "pd.to_pickle(data_to_save, 'GBIF_data.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
